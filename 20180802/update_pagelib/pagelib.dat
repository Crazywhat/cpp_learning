<?xml version="1.0" encoding="UTF-8"?>
<lib>
    <doc>
        <docid>0</docid>
        <title>如何重构“箭头型”代码</title>
        <link>http://coolshell.cn/articles/17757.html</link>
        <Content>本文主要起因是，一次在微博上和朋友关于嵌套好几层的if-else语句的代码重构的讨论（微博原文），在微博上大家有各式各样的问题和想法。按道理来说这些都是编程的基本功，似乎不太值得写一篇文章，不过我觉得很多东西可以从一个简单的东西出发，到达本质，所以，我觉得有必要在这里写一篇的文章。不一定全对，只希望得到更多的讨论，因为有了更深入的讨论才能进步。
文章有点长，我在文章最后会给出相关的思考和总结陈词，你可以跳到结尾。
所谓箭头型代码，基本上来说就是下面这个图片所示的情况。
那么，这样“箭头型”的代码有什么问题呢？看上去也挺好看的，有对称美。但是……
关于箭头型代码的问题有如下几个：
1）我的显示器不够宽，箭头型代码缩进太狠了，需要我来回拉水平滚动条，这让我在读代码的时候，相当的不舒服。
2）除了宽度外还有长度，有的代码的if-else里的if-else里的if-else的代码太多，读到中间你都不知道中间的代码是经过了什么样的层层检查才来到这里的。
总而言之，“箭头型代码”如果嵌套太多，代码太长的话，会相当容易让维护代码的人（包括自己）迷失在代码中，因为看到最内层的代码时，你已经不知道前面的那一层一层的条件判断是什么样的，代码是怎么运行到这里的，所以，箭头型代码是非常难以维护和Debug的。
微博上的案例 与 Guard Clauses
OK，我们先来看一下微博上的那个示例，代码量如果再大一点，嵌套再多一点，你很容易会在条件中迷失掉（下面这个示例只是那个“大箭头”下的一个小箭头）
FOREACH(Ptr&amp;lt;WfExpression&amp;gt;, argument, node-&amp;gt;arguments) {
    int index = manager-&amp;gt;expressionResolvings.Keys().IndexOf(argument.Obj());
    if (index != -1) {
        auto type = manager-&amp;gt;expressionResolvings.Values()[index].type;
        if (! types.Contains(type.Obj())) {
            types.Add(type.Obj());
            if (auto group = type-&amp;gt;GetTypeDescriptor()-&amp;gt;GetMethodGroupByName(L&amp;quot;CastResult&amp;quot;, true)) {
                int count = group-&amp;gt;GetMethodCount();
                for (int i = 0; i &amp;lt; count; i++) { auto method = group-&amp;gt;GetMethod(i);
                    if (method-&amp;gt;IsStatic()) {
                        if (method-&amp;gt;GetParameterCount() == 1 &amp;amp;&amp;amp;
                            method-&amp;gt;GetParameter(0)-&amp;gt;GetType()-&amp;gt;GetTypeDescriptor() == description::GetTypeDescriptor&amp;lt;DescriptableObject&amp;gt;() &amp;amp;&amp;amp;
                            method-&amp;gt;GetReturn()-&amp;gt;GetTypeDescriptor() != description::GetTypeDescriptor&amp;lt;void&amp;gt;() ) {
                            symbol-&amp;gt;typeInfo = CopyTypeInfo(method-&amp;gt;GetReturn());
                            break;
                        }
                    }
                }
            }
        }
    }
}
上面这段代码，可以把条件反过来写，然后就可以把箭头型的代码解掉了，重构的代码如下所示：
FOREACH(Ptr&amp;lt;WfExpression&amp;gt;, argument, node-&amp;gt;arguments) {
    int index = manager-&amp;gt;expressionResolvings.Keys().IndexOf(argument.Obj());
    if (index == -1)  continue;
    
    auto type = manager-&amp;gt;expressionResolvings.Values()[index].type;
    if ( types.Contains(type.Obj()))  continue;
    
    types.Add(type.Obj());
    auto group = type-&amp;gt;GetTypeDescriptor()-&amp;gt;GetMethodGroupByName(L&amp;quot;CastResult&amp;quot;, true);
    if  ( ! group ) continue;
 
    int count = group-&amp;gt;GetMethodCount();
    for (int i = 0; i &amp;lt; count; i++) { auto method = group-&amp;gt;GetMethod(i);
        if (! method-&amp;gt;IsStatic()) continue;
       
        if ( method-&amp;gt;GetParameterCount() == 1 &amp;amp;&amp;amp;
               method-&amp;gt;GetParameter(0)-&amp;gt;GetType()-&amp;gt;GetTypeDescriptor() == description::GetTypeDescriptor&amp;lt;DescriptableObject&amp;gt;() &amp;amp;&amp;amp;
               method-&amp;gt;GetReturn()-&amp;gt;GetTypeDescriptor() != description::GetTypeDescriptor&amp;lt;void&amp;gt;() ) {
            symbol-&amp;gt;typeInfo = CopyTypeInfo(method-&amp;gt;GetReturn());
            break;
        }
    }
}
这种代码的重构方式叫 Guard Clauses
Martin Fowler 的 Refactoring 的网站上有相应的说明《Replace Nested Conditional with Guard Clauses》。
Coding Horror 上也有一篇文章讲了这种重构的方式 —— 《Flattening Arrow Code》
StackOverflow 上也有相关的问题说了这种方式 —— 《Refactor nested IF statement for clarity》
这里的思路其实就是，让出错的代码先返回，前面把所有的错误判断全判断掉，然后就剩下的就是正常的代码了。
抽取成函数
微博上有些人说，continue 语句破坏了阅读代码的通畅，我觉得他们一定没有好好读这里面的代码，其实，我们可以看到，所有的 if 语句都是在判断是否出错的情况，所以，在维护代码的时候，你可以完全不理会这些 if 语句，因为都是出错处理的，而剩下的代码都是正常的功能代码，反而更容易阅读了。当然，一定有不是上面代码里的这种情况，那么，不用continue ，我们还能不能重构呢？
当然可以，抽成函数：
bool CopyMethodTypeInfo(auto &amp;amp;method, auto &amp;amp;group, auto &amp;amp;symbol) 
{
    if (! method-&amp;gt;IsStatic()) {
        return true;
    }
    if ( method-&amp;gt;GetParameterCount() == 1 &amp;amp;&amp;amp;
           method-&amp;gt;GetParameter(0)-&amp;gt;GetType()-&amp;gt;GetTypeDescriptor() == description::GetTypeDescriptor&amp;lt;DescriptableObject&amp;gt;() &amp;amp;&amp;amp;
           method-&amp;gt;GetReturn()-&amp;gt;GetTypeDescriptor() != description::GetTypeDescriptor&amp;lt;void&amp;gt;() ) {
        symbol-&amp;gt;typeInfo = CopyTypeInfo(method-&amp;gt;GetReturn());
        return false;
    }
    return true;
}
void ExpressionResolvings(auto &amp;amp;manager, auto &amp;amp;argument, auto &amp;amp;symbol) 
{
    int index = manager-&amp;gt;expressionResolvings.Keys().IndexOf(argument.Obj());
    if (index == -1) return;
    
    auto type = manager-&amp;gt;expressionResolvings.Values()[index].type;
    if ( types.Contains(type.Obj())) return;
    types.Add(type.Obj());
    auto group = type-&amp;gt;GetTypeDescriptor()-&amp;gt;GetMethodGroupByName(L&amp;quot;CastResult&amp;quot;, true);
    if  ( ! group ) return;
    int count = group-&amp;gt;GetMethodCount();
    for (int i = 0; i &amp;lt; count; i++) { auto method = group-&amp;gt;GetMethod(i);
        if ( ! CopyMethodTypeInfo(method, group, symbol) ) break;
    }
}
...
...
FOREACH(Ptr&amp;lt;WfExpression&amp;gt;, argument, node-&amp;gt;arguments) {
    ExpressionResolvings(manager, arguments, symbol)
}
...
...
你发出现，抽成函数后，代码比之前变得更容易读和更容易维护了。不是吗？
有人说：“如果代码不共享，就不要抽取成函数！”，持有这个观点的人太死读书了。函数是代码的封装或是抽象，并不一定用来作代码共享使用，函数用于屏蔽细节，让其它代码耦合于接口而不是细节实现，这会让我们的代码更为简单，简单的东西都能让人易读也易维护。这才是函数的作用。
嵌套的 if 外的代码
微博上还有人问，原来的代码如果在各个 if 语句后还有要执行的代码，那么应该如何重构。比如下面这样的代码。
for(....) {
    do_before_cond1()
    if (cond1) {
        do_before_cond2();
        if (cond2) {
            do_before_cond3();
            if (cond3) {
                do_something();
            }
            do_after_cond3();
        }
        do_after_cond2();
    }
    do_after_cond1();
}
上面这段代码中的那些 do_after_condX() 是无论条件成功与否都要执行的。所以，我们拉平后的代码如下所示：
for(....) {
    do_before_cond1();
    if ( !cond1 ) {
        do_after_cond1();
        continue
    } 
    do_after_cond1();
    do_before_cond2();
    if ( !cond2 ) { 
        do_after_cond2();
        continue;
    }
    do_after_cond2();
    do_before_cond3();
    if ( !cond3 ) {
        do_after_cond3();
        continue;
    }
    do_after_cond3();
    do_something();  
}
你会发现，上面的 do_after_condX 出现了两份。如果 if 语句块中的代码改变了某些do_after_condX依赖的状态，那么这是最终版本。
但是，如果它们之前没有依赖关系的话，根据 DRY 原则，我们就可以只保留一份，那么直接掉到 if 条件前就好了，如下所示：
for(....) {
    do_before_cond1();
    do_after_cond1();
    if ( !cond1 ) continue;
 
    do_before_cond2();
    do_after_cond2();
    if ( !cond2 ) continue;
    do_before_cond3();
    do_after_cond3();
    if ( !cond3 ) continue;
    do_something();  
}
此时，你会说，我靠，居然，改变了执行的顺序，把条件放到 do_after_condX() 后面去了。这会不会有问题啊？
其实，你再分析一下之前的代码，你会发现，本来，cond1 是判断 do_before_cond1() 是否出错的，如果有成功了，才会往下执行。而 do_after_cond1() 是无论如何都要执行的。从逻辑上来说，do_after_cond1()其实和do_before_cond1()的执行结果无关，而 cond1 却和是否去执行 do_before_cond2() 相关了。如果我把断行变成下面这样，反而代码逻辑更清楚了。
for(....) {
    do_before_cond1();
    do_after_cond1();
    if ( !cond1 ) continue;  // &amp;lt;-- cond1 成了是否做第二个语句块的条件
    do_before_cond2();
    do_after_cond2();
    if ( !cond2 ) continue; // &amp;lt;-- cond2 成了是否做第三个语句块的条件
    do_before_cond3();
    do_after_cond3();
    if ( !cond3 ) continue; //&amp;lt;-- cond3 成了是否做第四个语句块的条件
    do_something(); 
 
}
于是乎，在未来维护代码的时候，维护人一眼看上去就明白，代码在什么时候会执行到哪里。 这个时候，你会发现，把这些语句块抽成函数，代码会干净的更多，再重构一版：
bool do_func3() {
   do_before_cond2();
   do_after_cond2();
   return cond3;
}
bool do_func2() {
   do_before_cond2();
   do_after_cond2();
   return cond2;
}
bool do_func1() {
   do_before_cond1();
   do_after_cond1();
   return cond1;
}
// for-loop 你可以重构成这样
for (...) {
    bool cond = do_func1();
    if (cond) cond = do_func2();
    if (cond) cond = do_func3();
    if (cond) do_something();
}
// for-loop 也可以重构成这样
for (...) {
    if ( ! do_func1() ) continue;
    if ( ! do_func2() ) continue;
    if ( ! do_func3() ) continue;
    do_something();
}
上面，我给出了两个版本的for-loop，你喜欢哪个？我喜欢第二个。这个时候，因为for-loop里的代码非常简单，就算你不喜欢 continue ，这样的代码阅读成本已经很低了。
状态检查嵌套
接下来，我们再来看另一个示例。下面的代码的伪造了一个场景——把两个人拉到一个一对一的聊天室中，因为要检查双方的状态，所以，代码可能会写成了“箭头型”。
int ConnectPeer2Peer(Conn *pA, Conn* pB, Manager *manager)
{
    if ( pA-&amp;gt;isConnected() ) {
        manager-&amp;gt;Prepare(pA);
        if ( pB-&amp;gt;isConnected() ) {
            manager-&amp;gt;Prepare(pB);
            if ( manager-&amp;gt;ConnectTogther(pA, pB) ) {
                pA-&amp;gt;Write(&amp;quot;connected&amp;quot;);
                pB-&amp;gt;Write(&amp;quot;connected&amp;quot;);
                return S_OK;
            }else{
                return S_ERROR;
            }
        }else {
            pA-&amp;gt;Write(&amp;quot;Peer is not Ready, waiting...&amp;quot;);
            return S_RETRY;
        }
    }else{
        if ( pB-&amp;gt;isConnected() ) {
            manager-&amp;gt;Prepare();
            pB-&amp;gt;Write(&amp;quot;Peer is not Ready, waiting...&amp;quot;);
            return S_RETRY;
        }else{
            pA-&amp;gt;Close();
            pB-&amp;gt;Close();
            return S_ERROR;
        }
    }
    //Shouldn't be here!
    return S_ERROR;
}
重构上面的代码，我们可以先分析一下上面的代码，说明了，上面的代码就是对 PeerA 和 PeerB 的两个状态 “连上”， “未连上” 做组合 “状态” （注：实际中的状态应该比这个还要复杂，可能还会有“断开”、“错误”……等等状态）， 于是，我们可以把代码写成下面这样，合并上面的嵌套条件，对于每一种组合都做出判断。这样一来，逻辑就会非常的干净和清楚。
int ConnectPeer2Peer(Conn *pA, Conn* pB, Manager *manager)
{
    if ( pA-&amp;gt;isConnected() ) {
        manager-&amp;gt;Prepare(pA);
    }
    if ( pB-&amp;gt;isConnected() ) {
        manager-&amp;gt;Prepare(pB);
    }
    // pA = YES &amp;amp;&amp;amp; pB = NO
    if (pA-&amp;gt;isConnected() &amp;amp;&amp;amp; ! pB-&amp;gt;isConnected()  ) {
        pA-&amp;gt;Write(&amp;quot;Peer is not Ready, waiting&amp;quot;);
        return S_RETRY;
    // pA = NO &amp;amp;&amp;amp; pB = YES
    }else if ( !pA-&amp;gt;isConnected() &amp;amp;&amp;amp; pB-&amp;gt;isConnected() ) {
        pB-&amp;gt;Write(&amp;quot;Peer is not Ready, waiting&amp;quot;);
        return S_RETRY;
    // pA = YES &amp;amp;&amp;amp; pB = YES
    }else if (pA-&amp;gt;isConnected() &amp;amp;&amp;amp; pB-&amp;gt;isConnected()  ) {
        if ( ! manager-&amp;gt;ConnectTogther(pA, pB) ) {
            return S_ERROR;
        }
        pA-&amp;gt;Write(&amp;quot;connected&amp;quot;);
        pB-&amp;gt;Write(&amp;quot;connected&amp;quot;);
        return S_OK;
    }
    // pA = NO, pB = NO
    pA-&amp;gt;Close();
    pB-&amp;gt;Close();
    return S_ERROR;
}
延伸思考
对于 if-else 语句来说，一般来说，就是检查两件事：错误 和 状态。
检查错误
对于检查错误来说，使用 Guard Clauses 会是一种标准解，但我们还需要注意下面几件事：
1）当然，出现错误的时候，还会出现需要释放资源的情况。你可以使用 goto fail; 这样的方式，但是最优雅的方式应该是C++面向对象式的 RAII 方式。
2）以错误码返回是一种比较简单的方式，这种方式有很一些问题，比如，如果错误码太多，判断出错的代码会非常复杂，另外，正常的代码和错误的代码会混在一起，影响可读性。所以，在更为高组的语言中，使用 try-catch 异常捕捉的方式，会让代码更为易读一些。
检查状态
对于检查状态来说，实际中一定有更为复杂的情况，比如下面几种情况：
1）像TCP协议中的两端的状态变化。
2）像shell各个命令的命令选项的各种组合。
3）像游戏中的状态变化（一棵非常复杂的状态树）。
4）像语法分析那样的状态变化。
对于这些复杂的状态变化，其本上来说，你需要先定义一个状态机，或是一个子状态的组合状态的查询表，或是一个状态查询分析树。
写代码时，代码的运行中的控制状态或业务状态是会让你的代码流程变得混乱的一个重要原因，重构“箭头型”代码的一个很重要的工作就是重新梳理和描述这些状态的变迁关系。
总结
好了，下面总结一下，把“箭头型”代码重构掉的几个手段如下：
1）使用 Guard Clauses 。 尽可能的让出错的先返回， 这样后面就会得到干净的代码。
2）把条件中的语句块抽取成函数。 有人说：“如果代码不共享，就不要抽取成函数！”，持有这个观点的人太死读书了。函数是代码的封装或是抽象，并不一定用来作代码共享使用，函数用于屏蔽细节，让其它代码耦合于接口而不是细节实现，这会让我们的代码更为简单，简单的东西都能让人易读也易维护，写出让人易读易维护的代码才是重构代码的初衷！
3）对于出错处理，使用try-catch异常处理和RAII机制。返回码的出错处理有很多问题，比如：A) 返回码可以被忽略，B) 出错处理的代码和正常处理的代码混在一起，C) 造成函数接口污染，比如像atoi()这种错误码和返回值共用的糟糕的函数。
4）对于多个状态的判断和组合，如果复杂了，可以使用“组合状态表”，或是状态机加Observer的状态订阅的设计模式。这样的代码即解了耦，也干净简单，同样有很强的扩展性。
5） 重构“箭头型”代码其实是在帮你重新梳理所有的代码和逻辑，这个过程非常值得为之付出。重新整思路去想尽一切办法简化代码的过程本身就可以让人成长。
（全文完）
关注CoolShell微信公众账号可以在手机端搜索文章
（转载本站文章请注明作者和出处 酷 壳 &amp;#8211; CoolShell ，请勿用于任何商业用途）
——=== 访问 酷壳404页面 寻找遗失儿童。 ===——
</Content>
    </doc>
    <doc>
        <docid>1</docid>
        <title>AWS 的 S3 故障回顾和思考</title>
        <link>http://coolshell.cn/articles/17737.html</link>
        <Content></Content>
    </doc>
    <doc>
        <docid>2</docid>
        <title>从Gitlab误删除数据库想到的</title>
        <link>http://coolshell.cn/articles/17680.html</link>
        <Content>昨天，Gitlab.com发生了一个大事，某同学误删了数据库，这个事看似是个低级错误，不过，因为Gitlab把整个过程的细节都全部暴露出来了，所以，可以看到很多东西，而对于类似这样的事情，我自己以前也干过，而在最近的两公司中我也见过（Amazon中见过一次，阿里中见过至少四次），正好通过这个事来说说一下自己的一些感想和观点吧。我先放个观点：你觉得有备份系统就不会丢数据了吗？
事件回顾
整个事件的回顾Gitlab.com在第一时间就放到了Google Doc上，事后，又发了一篇Blog来说明这个事，在这里，我简单的回顾一下这个事件的过程。
首先，一个叫YP的同学在给gitlab的线上数据库做一些负载均衡的工作，在做这个工作时的时候突发了一个情况，Gitlab被DDoS攻击，数据库的使用飙高，在block完攻击者的IP后，发现有个staging的数据库(db2.staging)已经落后生产库4GB的数据，于是YP同学在Fix这个staging库的同步问题的时候，发现db2.staging有各种问题都和主库无法同步，在这个时候，YP同学已经工作的很晚了，在尝试过多个方法后，发现db2.staging都hang在那里，无法同步，于是他想把db2.staging的数据库删除了，这样全新启动一个新的复制，结果呢，删除数据库的命令错误的敲在了生产环境上（db1.cluster），结果导致整个生产数据库被误删除。（陈皓注：这个失败基本上就是 “工作时间过长” + “在多数终端窗口中切换中迷失掉了”）
在恢复的过程中，他们发现只有db1.staging的数据库可以用于恢复，而其它的5种备份机制都不可用，第一个是数据库的同步，没有同步webhook，第二个是对硬盘的快照，没有对数据库做，第三个是用pg_dump的备份，发现版本不对（用9.2的版本去dump 9.6的数据）导致没有dump出数据，第四个S3的备份，完全没有备份上，第五个是相关的备份流程是问题百出的，只有几个粗糙的人肉的脚本和糟糕的文档，也就是说，不但是是人肉的，而且还是完全不可执行的。（陈皓注：就算是这些备份机制都work，其实也有问题，因为这些备份大多数基本上都是24小时干一次，所以，要从这些备份恢复也一定是是要丢数据的了，只有第一个数据库同步才会实时一些）
最终，gitlab从db1.staging上把6个小时前的数据copy回来，结果发现速度非常的慢，备份结点只有60Mbits/S，拷了很长时间（陈皓注：为什么不把db1.staging给直接变成生产机？因为那台机器的性能很差）。数据现在的恢复了，不过，因为恢复的数据是6小时前的，所以，有如下的数据丢失掉了：
粗略估计，有4613 的项目， 74 forks,  和 350 imports 丢失了；但是，因为Git仓库还在，所以，可以从Git仓库反向推导数据库中的数据，但是，项目中的issues等就完全丢失了。
大约有±4979 提交记录丢失了（陈皓注：估计也可以用git仓库中反向恢复）。
可能有 707  用户丢失了，这个数据来自Kibana的日志。
在1月31日17:20 后的Webhooks 丢失了。
因为Gitlab把整个事件的细节公开了出来，所以，也得到了很多外部的帮助，2nd Quadrant的CTO &amp;#8211; Simon Riggs 在他的blog上也发布文章 Dataloss at Gitlab 给了一些非常不错的建议：
关于PostgreSQL 9.6的数据同步hang住的问题，可能有一些Bug，正在fix中。
PostgreSQL有4GB的同步滞后是正常的，这不是什么问题。
正常的停止从结点，会让主结点自动释放WALSender的链接数，所以，不应该重新配置主结点的 max_wal_senders 参数。但是，停止从结点时，主结点的复数连接数不会很快的被释放，而新启动的从结点又会消耗更多的链接数。他认为，Gitlab配置的32个链接数太高了，通常来说，2到4个就足够了。
另外，之前gitlab配置的max_connections=8000太高了，现在降到2000个是合理的。
pg_basebackup 会先在主结点上建一个checkpoint，然后再开始同步，这个过程大约需要4分钟。
手动的删除数据库目录是非常危险的操作，这个事应该交给程序来做。推荐使用刚release 的 repmgr
恢复备份也是非常重要的，所以，也应该用相应的程序来做。推荐使用 barman （其支持S3）
测试备份和恢复是一个很重要的过程。
看这个样子，估计也有一定的原因是——Gitlab的同学对PostgreSQL不是很熟悉。
随后，Gitlab在其网站上也开了一系列的issues，其issues列表在这里 Write post-mortem (这个列表可能还会在不断更新中)
infrastructure#1094 &amp;#8211; Update PS1 across all hosts to more clearly differentiate between hosts and environments
infrastructure#1095 &amp;#8211; Prometheus monitoring for backups
infrastructure#1096 &amp;#8211; Set PostgreSQL&amp;#8217;s max_connections to a sane value
infrastructure#1097 &amp;#8211; Investigate Point in time recovery &amp;amp; continuous archiving for PostgreSQL
infrastructure#1098 &amp;#8211; Hourly LVM snapshots of the production databases
infrastructure#1099 &amp;#8211; Azure disk snapshots of production databases
infrastructure#1100 &amp;#8211; Move staging to the ARM environment
infrastructure#1101 &amp;#8211; Recover production replica(s)
infrastructure#1102 &amp;#8211; Automated testing of recovering PostgreSQL database backups
infrastructure#1103 &amp;#8211; Improve PostgreSQL replication documentation/runbooks
infrastructure#1104 &amp;#8211; Kick out SSH users inactive for N minutes
infrastructure#1105 &amp;#8211; Investigate pgbarman for creating PostgreSQL backups
从上面的这个列表中，我们可以看到一些改进措施了。挺好的，不过我觉得还不是很够。
相关的思考
因为类似这样的事，我以前也干过（误删除过数据库，在多个终端窗口中迷失掉了自己所操作的机器……），而且我在amazon里也见过一次，在阿里内至少见过四次以上（在阿里人肉运维的误操作的事故是我见过最多的），但是我无法在这里公开分享，私下可以分享。在这里，我只想从非技术和技术两个方面分享一下我的经验和认识。
技术方面
人肉运维
一直以来，我都觉得直接到生产线上敲命令是一种非常不好的习惯。我认为，一个公司的运维能力的强弱和你上线上环境敲命令是有关的，你越是喜欢上线敲命令你的运维能力就越弱，越是通过自动化来处理问题，你的运维能力就越强。理由如下：
其一，如果说对代码的改动都是一次发布的话，那么，对生产环境的任何改动（包括硬件、操作系统、网络、软件配置……），也都算是一次发布。那么这样的发布就应该走发布系统和发布流程，要被很好的测试、上线和回滚计划。关键是，走发布过程是可以被记录、追踪和回溯的，而在线上敲命令是完全无法追踪的。没人知道你敲了什么命令。
其二，真正良性的运维能力是——人管代码，代码管机器，而不是人管机器。你敲了什么命令没人知道，但是你写个工具做变更线上系统，这个工具干了什么事，看看工具的源码就知道了。
另外、有人说，以后不要用rm了，要用mv，还有人说，以后干这样的事时，一个人干，另一个人在旁边看，还有人说，要有一个checklist的强制流程做线上的变更，还有人说要增加一个权限系统。我觉得，这些虽然可以work，但是依然不好，再由如下：
其一、如果要解决一个事情需要加更多的人来做的事，那这事就做成劳动密集型了。今天我们的科技就是在努力消除人力成本，而不是在增加人力成本。而做为一个技术人员，解决问题的最好方式是努力使用技术手段，而不是使用更多的人肉手段。人类区别于动物的差别就是会发明和使用现代化的工具，而不是使用更多的人力。另外，这不仅仅因为是，人都是会有这样或那样的问题（疲惫、情绪化、急燥、冲动……），而机器是单一无脑不知疲惫的，更是因为，机器干活的效率和速度是比人肉高出N多倍的。
其二、增加一个权限系统或是别的一个watch dog的系统完全是在开倒车，权限系统中的权限谁来维护和审批？不仅仅是因为多出来的系统需要多出来的维护，关键是这个事就没有把问题解决在root上。除了为社会解决就业问题，别无好处，故障依然会发生，有权限的人一样会误操作。对于Gitlab这个问题，正如2nd Quadrant的CTO建议的那样，你需要的是一个自动化的备份和恢复的工具，而不是一个权限系统。
其三、像使用mv而不rm，搞一个checklist和一个更重的流程，更糟糕。这里的逻辑很简单，因为，1）这些规则需要人去学习和记忆，本质上来说，你本来就不相信人，所以你搞出了一些规则和流程，而这些规则和流程的执行，又依赖于人，换汤不换药，2）另外，写在纸面上的东西都是不可执行的，可以执行的就是只有程序，所以，为什么不把checklist和流程写成代码呢？（你可能会说程序也会犯错，是的，程序的错误是consistent，而人的错误是inconsistent）
最关键的是，数据丢失有各种各样的情况，不单单只是人员的误操作，比如，掉电、磁盘损坏、中病毒等等，在这些情况下，你设计的那些想流程、规则、人肉检查、权限系统、checklist等等统统都不管用了，这个时候，你觉得应该怎么做呢？是的，你会发现，你不得不用更好的技术去设计出一个高可用的系统！别无它法。
关于备份
一个系统是需要做数据备份的，但是，你会发现，Gitlab这个事中，就算所有的备份都可用，也不可避免地会有数据的丢失，或是也会有很多问题。理由如下：
1）备份通常来说都是周期性的，所以，如果你的数据丢失了，从你最近的备份恢复数据里，从备份时间到故障时间的数据都丢失了。
2）备份的数据会有版本不兼容的问题。比如，在你上次备份数据到故障期间，你对数据的scheme做了一次改动，或是你对数据做了一些调整，那么，你备份的数据就会和你线上的程序出现不兼容的情况。
3）有一些公司或是银行有灾备的数据中心，但是灾备的数据中心没有一天live过。等真正灾难来临需要live的时候，你就会发现，各种问题让你live不起来。你可以读一读几年前的这篇报道好好感受一下《以史为鉴 宁夏银行7月系统瘫痪最新解析》
所以，在灾难来临的时候，你会发现你所设计精良的“备份系统”或是“灾备系统”就算是平时可以工作，但也会导致数据丢失，而且可能长期不用的备份系统很难恢复（比如应用、工具、数据的版本不兼容等问题）。
我之前写过一篇《分布式系统的事务处理》，你还记得下面这张图吗？看看 Data Loss 那一行的，在Backups, Master/Slave 和 Master/Master的架构下，都是会丢的。
所以说，如果你要让你的备份系统随时都可以用，那么你就要让它随时都Live着，而随时都Live着的多结点系统，基本上就是一个分布式的高可用的系统。因为，数据丢失的原因有很多种，比如掉电、磁盘损坏、中病毒等等，而那些流程、规则、人肉检查、权限系统、checklist等等都只是让人不要误操作，都不管用，这个时候，你不得不用更好的技术去设计出一个高可用的系统！别无它法。（重要的事，得再说一篇）
另外，你可以参看我的另一篇《关于高可用系统》，这篇文章中以MySQL为例，数据库的replication也只能达到 两个9。
AWS 的 S3 的的高可用是4个加11个9的持久性（所谓11个9的持久性durability，AWS是这样定义的，如果你存了1万个对象，那么丢一个的时间是1000万年），这意味着，不仅仅只是硬盘坏，机器掉电，整个机房挂了，其保证可以承受有两个设施的数据丢失，数据还是可用的。试想，如果你把数据的可用性通过技术做到了这个份上，那么，你还怕被人误删一个结点上的数据吗？
非技术方面
故障反思
一般说来，故障都需要反思，在Amazon，S2以上的故障都需要写COE（Correction of Errors），其中一节就是需要Ask 5 Whys，我发现在Gitlab的故障回顾的blog中第一段中也有说要在今天写个Ask 5 Whys。关于Ask 5 Whys，其实并不是亚马逊的玩法，这还是算一个业内常用的玩法，也就是说不断的为自己为为什么，直到找到问题的概本原因，这会逼着所有的当事人去学习和深究很多东西。在Wikipedia上有相关的词条 5 Whys，其中罗列了14条规则：
你需要找到正确的团队来完成这个故障反思。
使用纸或白板而不是电脑。
写下整个问题的过程，确保每个人都能看懂。
区别原因和症状。
特别注意因果关系。
说明Root Cause以及相关的证据。
5个为什么的答案需要是精确的。
寻找问题根源的步骤，而不是直接跳到结论。
要基础客观的事实、数据和知识。
评估过程而不是人。
千万不要把“人为失误”或是“工作不注意”当成问题的根源。
培养信任和真诚的气氛和文化。
不断的问“为什么”直到问题的根源被找到。这样可以保证同一个坑不会掉进去两次。
当你给出“为什么”的答案时，你应该从用户的角度来回答。
工程师文化
上述的这些观点，其实，我在我的以住的博客中都讲过很多遍了，你可以参看《什么是工程师文化？》以及《开发团队的效率》。其实，说白了就是这么一个事——如果你是一个技术公司，你就会更多的相信技术而不是管理。相信技术会用技术来解决问题，相信管理，那就只会有制度、流程和价值观来解决问题。
这个道理很简单，数据丢失有各种各样的情况，不单单只是人员的误操作，比如，掉电、磁盘损坏、中病毒等等，在这些情况下，你设计的那些流程、规则、人肉检查、权限系统、checklist等等统统都不管用，这个时候，你觉得应该怎么做呢？是的，你会发现，你不得不用更好的技术去设计出一个高可用的系统！别无它法。（重要的事得说三遍）
事件公开
很多公司基本上都是这样的套路，首先是极力掩盖，如果掩盖不了了就开始撒谎，撒不了谎了，就“文过饰非”、“避重就轻”、“转移视线”。然而，面对危机的最佳方法就是——“多一些真诚，少一些套路”，所谓的“多一些真诚”的最佳实践就是——“透明公开所有的信息”，Gitlab此次的这个事给大家树立了非常好的榜样。AWS也会把自己所有的故障和细节都批露出来。
事情本来就做错了，而公开所有的细节，会让大众少很多猜测的空间，有利于抵制流言和黑公关，同时，还会赢得大众的理解和支持。看看Gitlab这次还去YouTube上直播整个修复过程，是件很了不起的事，大家可以到他们的blog上看看，对于这样的透明和公开，一片好评。
（全文完）
关注CoolShell微信公众账号可以在手机端搜索文章
（转载本站文章请注明作者和出处 酷 壳 &amp;#8211; CoolShell ，请勿用于任何商业用途）
——=== 访问 酷壳404页面 寻找遗失儿童。 ===——
</Content>
    </doc>
    <doc>
        <docid>3</docid>
        <title>Chrome开发者工具的小技巧</title>
        <link>http://coolshell.cn/articles/17634.html</link>
        <Content>Chrome的开发者工具是个很强大的东西，相信程序员们都不会陌生，不过有些小功能可能并不为大众所知，所以，写下这篇文章罗列一下可能你所不知道的功能，有的功能可能会比较实用，有的则不一定，也欢迎大家补充交流。
话不多话，我们开始。
代码格式化
有很多css/js的代码都会被 minify 掉，你可以点击代码窗口左下角的那个 { }  标签，chrome会帮你给格式化掉。
强制DOM状态
有些HTML的DOM是有状态的，比如&amp;lt;a&amp;gt; 标签，其会有 active，hover， focus，visited这些状态，有时候，我们的CSS会来定关不同状态的样式，在分析网页查看网页上DOM的CSS样式时，我们可以点击CSS样式上的 :hov 这个小按钮来强制这个DOM的状态。
&amp;nbsp;
&amp;nbsp;
动画
现在的网页上都会有一些动画效果。在Chrome的开发者工具中，通过右上角的菜单中的 More Tools =&amp;gt; Animations 呼出相关的选项卡。于是你就可以慢动作播放动画了（可以点选 25% 或 10%），然后，Chrome还可以帮你把动画录下来，你可以拉动动再画的过程，甚至可以做一些简单的修改。
&amp;nbsp;
直接编辑网页
在你的 console 里 输入下面的命令：
document.designMode = &amp;quot;on&amp;quot; 
于是你就可以直接修改网页上的内容了。
P.S. 下面这个抓屏中还演示了一个如何清空console的示例。你可以输入 clear() 或是 按 Ctrl+L（Windows下），CMD + K (Mac下)
&amp;nbsp;
网络限速
你可以设置你的网络的访问速度来模拟一个网络很慢的情况。
&amp;nbsp;
复制HTTP请求
这个是我很喜欢 的一个功能，你可以在 network选项卡里，点击 XHR 过滤相关的Ajax请求，然后在相关的请求上点鼠标右键，在菜单中选择： Copy =&amp;gt; Copy as cURL，然后就可以到你的命令行下去 执行 curl 的命令了。这个可以很容易做一些自动化的测试。
&amp;nbsp;
友情提示：这个操作有可能会把你的个人隐私信息复制出去，比如你个人登录后的cookie。
抓个带手机的图
这个可能有点无聊了，不过我觉得挺有意思的。
在device显示中，先选择一个手机，然后在右上角选 Show Device Frame，然后你就看到手机的样子了，然后再到那个菜中中选 Capture snapshot，就可以抓下一个有手机样子的截图了。
我抓的图如下（当然，不是所有的手机都有frame的）
&amp;nbsp;
设置断点
除了给Javascript的源代码上设置断点调试，你还可以：
给DOM设置断点
选中一个DOM，然后在右键菜单中选 Break on &amp;#8230; 你可以看到如下三个选项：
给XHR和Event Lisener设置断点
在 Sources 面页中，你可以看到右边的那堆break points中，除了上面我们说的给DOM设置断点，你还可以给XHR和Event Listener设置断点，载图如下：
关于Console中的技巧
DOM操作
chrome会帮你buffer 5个你查看过的DOM对象，你可以直接在Console中用 $0, $1, $2, $3, $4来访问。
你还可以使用像jQuery那样的语法来获得DOM对象，如：$("#mydiv")
你还可使用 $$(".class") 来选择所有满足条件的DOM对象。
你可以使用 getEventListeners($("selector")) 来查看某个DOM对象上的事件（如下图所示）。
你还可以使用 monitorEvents($("selector")) 来监控相关的事件。比如：
monitorEvents(document.body, &amp;quot;click&amp;quot;);
Console中的一些函数
1）monitor函数
使用 monitor函数来监控一函数，如下面的示例
2）copy函数
copy函数可以把一个变量的值copy到剪贴板上。
3）inspect函数
inspect函数可以让你控制台跳到你需要查看的对象上。如：
更多的函数请参数官方文档 &amp;#8211; Using the Console / Command Line Reference
Console的输出
我们知道，除了console.log之外，还有console.debug，console.info，console.warn，console.error这些不同级别的输出。另外一个鲜为人知的功能是，console.log中，你还可以对输出的文本加上css的样式，如下所示：
console.log(&amp;quot;%c左耳朵&amp;quot;, &amp;quot;font-size:90px;color:#888&amp;quot;)
于是，你可以定义一些相关的log函数，如：
console.todo = function( msg){
  console.log( '%c%s %s %s', 'font-size:20px; color:yellow; background-color: blue;', '--', msg, '--');
}
console.important = function( msg){
  console.log( '%c%s %s %s', 'font-size:20px; color:brown; font-weight: bold; text-decoration: underline;', '--', msg, '--');
}
关于console.log中的格式化，你可以参看如下表格：
指示符
输出
%s
格式化输出一个字符串变量。
%i or %d
格式化输出一个整型变量的值。
%f
格式化输出一个浮点数变量的值。
%o
格式化输出一个DOM对象。
%O
格式化输出一个Javascript对象。
%c
为后面的字符串加上CSS样式
&amp;nbsp;
除了console.log打印js的数组，你还可以使用console.table来打印，如下所示：
var pets = [
  { animal: 'Horse', name: 'Pony', age: 23 },
  { animal: 'Dog', name: 'Snoopy', age: 13 },
  { animal: 'Cat', name: 'Tom', age: 18 },
  { animal: 'Mouse', name: 'Jerry', age: 12}
];
console.table(pets)
&amp;nbsp;
关于console对象
console对象除了上面的打日志的功能，其还有很多功能，比如：
console.trace() 可以打出js的函数调用栈
console.time() 和 console.timeEnd() 可以帮你计算一段代码间消耗的时间。
console.profile() 和 console.profileEnd() 可以让你查看CPU的消耗。
console.count() 可以让你看到相同的日志当前被打印的次数。
console.assert(expression, object) 可以让你assert一个表达式
这些东西都可以看看Google的Console API的文档。
其实，还有很多东西，你可以参看Google的官方文档 &amp;#8211; Chrome DevTools
关于快捷键
点击在 DevTools的右上角的那三个坚排的小点，你会看到一个菜单，点选 Shortcuts，你就可以看到所有的快捷键了
如果你知道更多，也欢迎补充！
（全文完）
关注CoolShell微信公众账号可以在手机端搜索文章
（转载本站文章请注明作者和出处 酷 壳 &amp;#8211; CoolShell ，请勿用于任何商业用途）
——=== 访问 酷壳404页面 寻找遗失儿童。 ===——
</Content>
    </doc>
    <doc>
        <docid>4</docid>
        <title>从 MongoDB “赎金事件” 看安全问题</title>
        <link>http://coolshell.cn/articles/17607.html</link>
        <Content>今天上午（2017年1月7日），我的微信群中同时出现了两个MongoDB被黑掉要赎金的情况，于是在调查过程中，发现了这个事件。这个事件应该是2017年开年的第一次比较大的安全事件吧，发现国内居然没有什么报道，国内安全圈也没有什么动静（当然，他们也许知道，只是不想说吧），Anyway，让我这个非安全领域的人来帮补补位。
事件回顾
这个事情应该是从2017年1月3日进入公众视野的，是由安全圈的大拿 Victor Gevers （网名：0xDUDE，GDI.foundation 的Chairman），其实，他早在2016年12月27日就发现了一些在互联网上用户的MongoDB没有任何的保护措施，被攻击者把数据库删除了，并留下了一个叫 WARNING 的数据库，这张表的内容如下：
{
    "_id" : ObjectId("5859a0370b8e49f123fcc7da"),
    "mail" : "harak1r1@sigaint.org",
    "note" : "SEND 0.2 BTC TO THIS ADDRESS 13zaxGVjj9MNc2jyvDRhLyYpkCh323MsMq AND CONTACT THIS EMAIL WITH YOUR IP OF YOUR SERVER TO RECOVER YOUR DATABASE !"
}
基本上如下所示：
MongoDB ransom demand (via Victor Gevers)
说白了就是黑客留下的东西——老子把你的MongoDB里的数据库给转走了，如果你要你的数据的话，给我0.2个的比特币（大约USD200）。然后，他的twitter上不断地发布这个“赎金事件”的跟踪报道。与此同时，中国区的V2EX上也发现了相关的攻击问题 《自己装的 mongo 没有设置密码结果被黑了》
然后，在接下来的几天内，全球大约有1800个MongoDB的数据库被黑，这个行为来自一个叫 Harak1r1 的黑客组织（这个组织似乎就好黑MongoDB，据说他们历史上干了近8500个MongoDB的数据库，几乎都是在祼奔的MongoDB）。
不过，这个组织干了两天后就停手了，可能是因为这事已经引起了全球科技媒体的注意，产生了大量的报道（如果你在Google News里查一下“mongodb ransom”，你会看到大量的报道（中文社区中，只有台湾有相关的报道）），他们也许是不敢再搞下去了。
不过，很快，有几个copycats开始接着干，
马上跟进的是 own3d ，他们留下的数据库的名字叫 WARNING_ALERT，他们至少干掉了 930个MongoDB，赎金0.5个比特币（USD500），至少有3个用户付费了
然后是0704341626asdf，他们留下的数据库名字叫PWNED，他们至少干掉了740个MongoDB，赎金0.15个比特币（USD150），看看他们在数据库里留下的文字——你的MongoDB没有任何的认证，并且暴露在公网里（你TMD是怎么想的？）……
0704341626asdf group ransom note (via Victor Gerves)
就在这两天，有两个新的黑客也来了
先是kraken0，发现到现在1天了，干了13个MongoDB，赎金 0.1个比特币。
然后是 3lix1r，发现到现在5个小时，干了17个MongoDB，赎金0.25比特币。
BBC新闻也于昨天报道了这一情况——《Web databases hit in ransom attacks》，现在这个事情应该是一个Big News了。
关于MongoDB的安全
安全问题从来都是需要多方面一起努力，但是安全问题最大的短板就是在用户这边。这次的这个事，说白了，就是用户没有给MongoDB设置上用户名和口令，然后还把服务公开到了公网上。
是的，这个安全事件，相当的匪夷所思，为什么这些用户要在公网上祼奔自己的数据库？他们的脑子是怎么想的？
让我们去看一下Shodan上可以看到的有多少个在暴露在公网上而且没有防范的MongoDB？我了个去！4万7千个，还是很触目惊心的（下图来自我刚刚创建的 Shodan关于MongoDB的报表）
&amp;nbsp;
那么，怎么会有这么多的对外暴露的MongoDB？看了一下Shodan的报告，发现主要还是来自公有云平台，Amazon，Alibaba，Digital Ocean，OVH，Azure 的云平台上有很多这样的服务。不过，像AWS这样的云平台，有很完善的默认安全组设置和VPC是可以不把这样的后端服务暴露到公有云上的，为什么还会有那么多？
&amp;nbsp;
这么大量的暴露在公网上的服务是怎么回事？有人发现（参看这篇文章《It&amp;#8217;s the Data, Stupid!》 ），MongoDB历史上一直都是把侦听端口绑在所有的IP上的，这个问题在5年前（2011年11月）就报给了MongoDB (SERVER-4216)，结果2014年4月才解决掉。所以，他觉得可能似乎 MongoDB的 2.6之前的版本都会默认上侦听在0.0.0.0 。
于是我做了一个小试验，到我的Ubuntu 14.04上去 apt-get install mongodb（2.4.9版），然后我在/etc/mongodb.conf 文件中，看到了默认的配置是127.0.0.1，mongod启动也侦听在了127.0.0.1这台机器上。一切正常。不过，可能是时过境迁，debain的安装包里已加上了这个默认配置文件。不管怎么样，MongoDB似乎是有一些问题的。
再到Shodan上看到相关的在公网裸奔的MongoDB的版本如下，发现3.x的也是主流：
&amp;nbsp;
虽然，3.x的版本成为了主流，但是似乎，还是有很多人把MongoDB的服务开到了互联网上来，而且可以随意访问。
你看，我在阿里云随便找了几台机器，一登就登上去了。
真是如那些黑客中的邮件所说的：WTF，你们是怎么想的？
后续的反思
为什么还是有这么多的MongoDB在公网上祼奔呢？难道有这么多的用户都是小白？这个原因，是什么呢？我觉得可能会是如下两个原因：
1）一是技术人员下载了mongod的软包，一般来说，mongodb的压缩包只有binary文件 ，没有配置文件 ，所以直接解开后运行，结果就没有安全认证，也绑在了公网上。也许，MongoDB这么做的原因就是为了可以快速上手，不要在环境上花太多的时间，这个有助于软件方面的推广。但是，这样可能就坑了更多的人。
2）因为MongoDB是后端基础服务，所以，需要很多内部机器防问，按道理呢，应该绑定在内网IP上，但是呢，可能是技术人员不小心，绑在了0.0.0.0的IP上。
那么，这个问题在云平台上是否可以更好的解决呢？
关于公网的IP。一般来说，公有云平台上的虚拟主机都会有一个公网的IP地址，老实说，这并不是一个好的方法，因为有很多主机是不需要暴露到公网上的，所以，也就不需要使用公网IP，于是，就会出现弹性IP或虚拟路由器以及VPC这样的虚拟网络服务，这样用户在公有云就可以很容易的组网，也就没有必要每台机器都需要一个公网IP，使用云平台，最好还是使用组网方案比较好的平台。
关于安全组。在AWS上，你开一台EC2，会有一个非常严格的安全组——只暴露22端口，其它的全部对外网关闭。这样做，其实是可以帮用户防止一下不小心把不必要的服务Open到公网上。按道理来说，AWS上应该是帮用户防了这些的。但是，AWS上的MongoDB祼奔的机器数量是最多的，估计和AWS的EC2的 基数有关系吧（据说AWS有千万台左右的EC2了）
最后，提醒大家一下，被黑了也不要去付赎金，因为目前来说没有任何证据证明黑客们真正保存了你的数据，因为，被黑的服务器太多了，估计有几百T的数据，估计是不会为你保存的。下面也是Victor Gevers的提示：
（全文完）
关注CoolShell微信公众账号可以在手机端搜索文章
（转载本站文章请注明作者和出处 酷 壳 &amp;#8211; CoolShell ，请勿用于任何商业用途）
——=== 访问 酷壳404页面 寻找遗失儿童。 ===——
</Content>
    </doc>
    <doc>
        <docid>5</docid>
        <title>技术人员的发展之路</title>
        <link>http://coolshell.cn/articles/17583.html</link>
        <Content></Content>
    </doc>
    <doc>
        <docid>6</docid>
        <title>如何读懂并写出装逼的函数式代码</title>
        <link>http://coolshell.cn/articles/17524.html</link>
        <Content></Content>
    </doc>
    <doc>
        <docid>7</docid>
        <title>什么是工程师文化？</title>
        <link>http://coolshell.cn/articles/17497.html</link>
        <Content> 四年前，我在QCon上演讲了一个《建一支强大的小团队》（整理后的PPT分享于这里）提到了工程师文化，今天，我想在这里再写一篇关于工程师文化的文章，一方面是因为我又有了一些想法和体会，另一方面，因为我也正走在创业的道路，毫无疑问，要建一个有浓重的工程师文化的团队或公司，所以有必要把自己的相关想法形有成白底黑字的“字据”，以供打自己的脸——“要是未来没有做到，这篇文章就打我未来的脸” || “这篇文章太幼稚了，未来的我会打我现在的脸”，当然，如果要打脸，我希望是前者。
Again，这篇文章不是招人的贴子，因为我觉得，招聘第一重要的事，不是发招聘广告或是找猎头挖人，而是先得让自己变成一个能配得上真正工程师的公司，然后再谈吸引人的事。
为什么要工程师文化
看看最近二十年来社会的发展，计算机和互联网已经渗透到了这个社会的每一个角落，各式各样的计算机技术成为了整个世界发展的强大引擎，各式各样的创新，无论是业务创新还是技术创新，都是依托于技术的快速演进，技术成了解放生产力提高社会运作的效率的中坚力量。以美帝为首的技术创新公司着着实实的改变着这个世界和人类的生活和生产习惯。
今天，每个从事计算机行业的技术人员都应该感到幸运，因为，我们不但选对了行业，也出生在了正确的时代，可以感受到前所未有的刺激和变化，相比起我们的父辈，我们的人生，能经历这样的时代，实在是一种幸运。所以，选对了职业并出生在了正确的年代的我们，此时只需要思考的一个问题，那就是，我是否呆在了正确的地方用正确的方式做事？
在我看来，这个世界上有三种商业公司，
运营或销售驱动型的公司。这类的公司以运营和营销见长，技术对于他们来说，更多的只是为了支持大规模的营销活动，以及成本上的控制，所以，基本上来说不太需要技术创新。这种公司最大的问题就是缺乏安全感。
产品驱动型的公司。这类公司以产品见长，通过创造能提升用户生活体验的产品见长，技术对于他们来说，除了支持大规模的在线用户之外，他们会更多的去寻找那些为了增强用户体验，提高整个业务流程效率的技术创新。比如：UI的交互方面的，整个业务流程方面的。这种公司最大的问题，就是容易被别人模仿和抄袭。
技术驱动型的公司。这类的公司相信技术能改变世界，他们更多的是用强大的工程技术来创造有颠覆性的东西，更多的是用各种自动化的技术取代人类。比如：近代的蒸汽机技术取代了大量的人工，数字技术取代了大量信息传递的人工，现代，这类公司还希望通过人工智能来取代愚蠢的人类来做决定。这种公司最大的问题就是可能做出叫好不叫座的东西。
这三种公司都可能成功，也都有问题，但是，无一例外，他们都需要强大的技术支撑，只不过，他们把技术所放在的位置不一样。
无论你有多么的看不起技术人员，你都无法否认，你今天的生活相当的依赖这帮工程师，没有他们，你恐怕都不知道怎么生活了。邓爷爷几十年前就说过——“科学技术是第一生产力” ，无论什么样的科学技术的理论要落地都会依赖于工程技术有多先进。
所以，在今天，作为一个IT或互联网公司，“工程师文化”不是一个问题，而是一个常识！
工程师文化的特征
我下面罗列的这些特征，来源于：Google的《重新定义公司》，我在Amazon的工作经历，37Signals的《Rework》，Quora上的 What Makes Good Engineering Culture?  Slideshare上的 What Makes Good Engineering Culture，以及我最近这半年来的一些实践。
简单说来，我可以简单的把这多的工程师文化的总结成两大类：“自由” 和 “效率”。
本来还应该有个“创新”，但我个人认为，创新的前提是——在自由的环境下对提高效率的痴迷，就一定会发生创新。
创新不是凭空出现新的东西，其实，观察一下人类的发展史，不难发现，几乎所有的创新基本上跳出原来的思维模式用新的思维模式对原有问题的效率进行质的提升。比如：通信、交通、医疗、教育、生活……几乎全都是在优化效率。
所以，如果你的精神不自由，你很难跳出老的思维模式，你用老的思维模式你一定不会想到新的方法和方式，如果不是对效率的提升，这个创新可能会不接地气。
因此，我认为，工程师文化就是自由加效率！
自由
首先，工程师文化意味的创新文化，工程师都是有创新冲动的人，因为手里有创造技能的人通常都会有想创造点什么的冲动。而创新的源泉水来源于精神的解放，精神自由才会引发各式各样的奇思怪想，才会有常人觉得不可能的疯狂想法和想像力，而这些想法和想像力导致了创新。
精神上的自由具体表现在：
自我驱动。自己管理自己是最好的管理。最失败的管理就是家长和保姆式的管理。兴趣出发的工作才可能迸发出真正的动力。
灵活的工作时间和地点。工程师们更多的是脑力工作，而不是体力工作，工作上时间和地点的自由安排可以让工程师们的脑力工作更有效。Remote是一个很不错的工作方式，开源社区基本上都是这钟方式。和Remote有关的话题可参看37Signals的这本书《Remote》
</Content>
    </doc>
    <doc>
        <docid>8</docid>
        <title>关于高可用的系统</title>
        <link>http://coolshell.cn/articles/17459.html</link>
        <Content></Content>
    </doc>
    <doc>
        <docid>9</docid>
        <title>这多年来我一直在钻研的技术</title>
        <link>http://coolshell.cn/articles/17446.html</link>
        <Content>因为我是看到tinyfool 《那些年我赶过的时髦技术趋势》，在赞叹的时候，也让我对我有好些回忆，所以想写一篇回忆贴，本来觉得回忆是件挺让人沮喪的事，因为是老了的表现，但我写着写着，就歪了楼。看来，我还不老，还在拼博。下面是很多我的唠叨，你喜欢就读读，不喜欢就TLDR &amp;#8211; Too Long, Don&amp;#8217;t Read!
自从98年毕业，到今天，参加工作有18个年头了，加上在大三的时候就为两个在外面接活的老师程序，到今天，写的程序被用到生产线也有18个年头了。
背景经历
要说明我技术上的“性取向”，还得我说说的我的一些背景和经历。
我这18年，大约分三个阶段：
1996年-2000年：入门乱来期，大三大四加在银行工作的两年。
用Powerbuilder/Delphi在WindowsNT/SQL Server上做了好多个MIS管理软件，有酒店的，有送水的，有OA的。
 用Java的Applet做了一个Web的教学课件，用于在Win95/IE3.0中演示操作系统中的各种调度和算法的动画，得了个全国大学生挑战者杯的鼓励奖。
 用Delphi的ISAPI技术以及PHP/ASP给一些公司和大学做过几个网站。
2000年-2010年：技术学习期，这十年，我主要的编程语言是C/C++。
前两年在银行用C语言在Unix（AIX/Solaris/Sco Unix/HP-UX..）写各种银行业务（用C语言写），用C写操作SQL，操作界面，写业务交易逻辑，一切都用C……，这是一个C语言的年代，当时，全国的银行都在做大集中，银行是当时行业里最大的软件系统了，所以，我确定了C/C++/Unix的技术方向，我当时的网上签名是，C/C++/Unix才是大规模杀伤性武器。
然后，2002年在Platform做一个全平台的（包括Unix/Linux/Windows）高性能计算的软件产品，很像今天的Hadoop，当时叫Grid Computing，主要用低廉的x86集群进行大规模的并行计算，主要用于芯片设计行业，如：ARM和德州仪器，或是科研，如NASA，或是国家安全，如美国国防部的影像分析，或是3D动画渲染，如怪物史瑞克……从05年以后，发现很多用户开始从Unix迁移到Linux，于是开始更为关注Linux的Kernel知识。Platform有一套很严谨的软件工程体系，我对严谨的软件工程以及很多的基础的技术的认识在这里形成。
2007年在路透做路透全球金融数据Real-Time网络的高性能调优（我在《性能测试应该怎么做？》一文中透露过这个公司的性能要求，是一个实时的数据网络，对于99.9%的网络传输在100K的tps下要低于1ms，技术挑战是很大的），在路透，我只干一个事，就是性能优化，我把我负责的几个系统的性能都提升了8倍到15倍的样子，09年年底的时候，我已把未来3年的优化的活都干完了。所以，这个时期，我也开始了我的经理生涯。我对性能调优，高可用系统架构，研发管理的很多是在这里形成的。
2010年到今天，技术沉淀期，这个时间段，主要的编程语言是Java。
这段时间，我加入了Amazon和Alibaba，也就是所谓的互联网公司。在Amazon干了两个事，一个是把Amazon全球的marketplace连起来，跨大洲的数据中心的通信，还有一个是第一次接触大数据和机器学习——用户需求预测系统。在Alibaba干过电商云平台聚石塔和阿里云，去阿里最主要的是经历双十一。
这段时间，对我影响比较大的是Amazon，技术不再是我的瓶颈，大规模的系统，对我也不是问题，而让我收获最大的是，世界前沿的软件设计架构和解决方案，以及做技术的态度和工程的方法，我的眼界、脑洞和视野都巨大的打开，并且在技术管理、工程管理、产品管理、人员管理、公司管理等等管理方面的思维有了质的提升。这段时间，才是我真正技术沉淀的时期。
我的这个背景本来可以更好一些，只可惜运气不太好，本来可以走的更快的，无奈在最关键的时候遇到了两次金融危机，本来可以去硅谷更牛更好的公司见世面，无奈父母身体欠安，只能放弃。
经历决定思维方式
通过我的背景经历，大家不难看到，我基本上都是做一些规模比较大的系统和软件，而且，主要用C/C++/Unix/Linux这样比较晦涩的语言和操作系统。我们知道用C和C++开发，基本上要处理的错误都是和系统底层相应的东西，而上规模的系统和软件，又总是会遇到很多“稀奇古怪”的问题，这些问题，都会逼着我要去了解很多的操作系统、计算机系统、网络、数据库、中间件等等的各种基础或底层技术。
而且我经历的基本上都是非常严谨的软件工程，不能马虎，我有几次马虎的经历，给我造成了非常大的心理影响，比如，曾经被定性为不适合写代码，因为我的代码太烂，或是出了严重的故障，几乎要跑路去了。另外，全球gloabl式的oncall，经常让我在凌晨被电话叫起来解决问题，这个经历比较痛苦。所以，我的整个经历，让我养成了，在软件开发上必需也不得不严谨的习惯和价值观体系。
大家想想，用C/C++开发一个几乎不能出故障的软件系统，你需要多仔细和多严谨的态度才能达到要求？因此，我的经历让我不能马虎，也不能应付工作，更不能在标准上有所妥协，还需要不断地提高标准，所以，时间一长，我必然，会有如下的习惯：
要做到——知其然，知其所以然。所以，只能不断的学习基础知识以及和这个技术关联的知识，就像Wikipeida一样，当你进入一个词条的时候，就会伴随时一堆新词条，于是，当多年后，我看到 “知识广度是深度的副产品”这句话时，简直就是说到我的心里去了。
要做出工业级的软件。从银行到Platform到Thomson Reuters再到Amazon，软件开发上都会有SLA的要求。我认为，一个软件是工业级还是民用级的，除了功能正确之外，最重要的一个指标之一就是在性能和稳定性上有没有SLA。绝大多数的互联网公司和开源软件都没有SLA。所以，达不到工业级的标准。要达到工业级的标准，就需要花费时间、人力和财力进行非常繁琐的设计、测试评估以及运维管理。
工业级的软件来自工业级专业人员和专业软件工程。
专业的人员。为什么绝大多数的外国公司需要的是CS（Computer Science）背景毕业的工程师？因为他们要做的是工业级的软件，这是一门科学，即然是科学，就需要受过良好的科学教育的CS专业的人。
专业的工程。工业级的软件需要有工业级的软件工程，比如，严谨的Design/Code Review，严格的测试，以及完备的线上运维。
专业的工具。这个时候，你就会发现，要做到高级别的SLA，比如包括5个9以上的SLA，人肉干活的能力已经完全跟不上了，你需要大量的专业的与之配套工具。人类之所以聪明是因为会发明工具，所以，这也是工业级的另一个标准——你有多少现代化的支撑工具？
在之前的《开发团队的效率》一文中，我说过——你总需要在一个环节上认真，这个环节越往前就越有效率，越往后你就越没效率。要么你设计和编码认真点，不然，你就得在测试上认真点。要是你设计、编码、测试都不认真，那你就得在运维上认真，就得在处理故障上认真。你总需要在一个地方认真。
认真是痛苦和艰难的，也是需要苦苦坚持的，因为人太容易妥协了，这对每个人来说都是一种不小的挑战。老实说，我与很多人对“认真”的标准不一样，所以，产生了很多分歧，很多人说我太理想了。其实，我能理解他们，一方面是因为我的标准是比较高了，另一方面是他们只做过民用级的软件。
另外，在一开始，做惯了工业级软件的我极度地不适应于那些糙快猛的开发方式。不过，我也在调整自己，毕竟，世界不只一种价值观，有的是工业级的软件，有的则是民用级的，还有的只是个玩具，而且还有Java这门语言非常有效地屏蔽了很多底层和基础知识，所以，也不可一概而论，我也在适应一些民用级的软件开发的方式。
后记
从去年我从阿里离开到现在14个月了，这段时间内，我给大约40多家公司做过相应的技术咨询和解决过很多技术问题，绝大多数公司都是因为性能和稳定性的问题来找我的，我给这些公司解决问题的时候，基本都是这样的Pattern：
一开始，发现都是一些技术知识点的问题，
然后，马上进入到系统架构方面方面的问题，
当再解决架构问题的时候，我发现，已经是软件工程的问题，
而软件工程问题的后面，又是公司管理上的问题
而公司管理的问题，结果又到了人的问题上
而人的问题，又到了公司文化的问题……
你看，很多问题，一环扣一环，最终都不是一个简单的技术问题。我倒不是说，我在抱怨这些问题，我更不是在说能解决这些问题，因为，就像软件工程没有银弹一样，无论你给什么样的解决方案都会有问题，没有问题才是不科学的。我能做的是，观察这个公司的业务形态、和相关的思维方式，以及现有的资源和相应的技术实力，帮助他们从技术到管理上缓解或改善现有的问题。
所以，我基本上来说，这近20年来，我只在专心研究一个事——如何做出一个性能高稳定性好的大规模的系统。在这个方向中，除了很多的基础和底层技术我需要吃透，我还需要在软件的开发工艺，软件工具，以及软件的线上运维，以及相关的管理上不断学习和思考，因为，只有技术、工具、工程、运维、人员这几个方面搞好了，才可能出现一个性能高且稳定性好的系统。
之前对于我来说，我一直在鼓吹先进的管理和软件工程以及技术和工具。今天，对我来说，遇到最大的问题就是，在没有这些所谓的先进的东西的时候，除了我自己上手外，我是否还能解决相应的问题？因为我自己已经完全Scale不开了。
有问题就有挑战，我每天都在思考，如何在不完美甚至残缺的环境下，解决这些公司的技术问题。每个人都要给自己一个目标。目前，我给自己的目标是——在残缺的环境下，能让用户不改一行代码，不动任何的架构，不改变用户很糟糕的软件开发的习惯，也不让用户作任何管理上的调整，能提升用户的软件系统的性能和稳定性。
因为我相信技术，我相信有更好的技术，可以为用户完全透明的提升性能和稳定性，我大致找到了相应的解，现在，我正在实践的路上，这也许是笔大买卖，所以我不知天高地厚地注册了自己的公司……
（全文完）
关注CoolShell微信公众账号可以在手机端搜索文章
（转载本站文章请注明作者和出处 酷 壳 &amp;#8211; CoolShell ，请勿用于任何商业用途）
——=== 访问 酷壳404页面 寻找遗失儿童。 ===——
</Content>
    </doc>
    <doc>
        <docid>10</docid>
        <title>缓存更新的套路</title>
        <link>http://coolshell.cn/articles/17416.html</link>
        <Content>看到好些人在写更新缓存数据代码时，先删除缓存，然后再更新数据库，而后续的操作会把数据再装载的缓存中。然而，这个是逻辑是错误的。试想，两个并发操作，一个是更新操作，另一个是查询操作，更新操作删除缓存后，查询操作没有命中缓存，先把老数据读出来后放到缓存中，然后更新操作更新了数据库。于是，在缓存中的数据还是老的数据，导致缓存中的数据是脏的，而且还一直这样脏下去了。
我不知道为什么这么多人用的都是这个逻辑，当我在微博上发了这个贴以后，我发现好些人给了好多非常复杂和诡异的方案，所以，我想写这篇文章说一下几个缓存更新的Design Pattern（让我们多一些套路吧）。
这里，我们先不讨论更新缓存和更新数据这两个事是一个事务的事，或是会有失败的可能，我们先假设更新数据库和更新缓存都可以成功的情况（我们先把成功的代码逻辑先写对）。
更新缓存的的Design Pattern有四种：Cache aside, Read through, Write through, Write behind caching，我们下面一一来看一下这四种Pattern。
Cache Aside Pattern
这是最常用最常用的pattern了。其具体逻辑如下：
失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
命中：应用程序从cache中取数据，取到后返回。
更新：先把数据存到数据库中，成功后，再让缓存失效。
注意，我们的更新是先更新数据库，成功后，让缓存失效。那么，这种方式是否可以没有文章前面提到过的那个问题呢？我们可以脑补一下。
一个是查询操作，一个是更新操作的并发，首先，没有了删除cache数据的操作了，而是先更新了数据库中的数据，此时，缓存依然有效，所以，并发的查询操作拿的是没有更新的数据，但是，更新操作马上让缓存的失效了，后续的查询操作再把数据从数据库中拉出来。而不会像文章开头的那个逻辑产生的问题，后续的查询操作一直都在取老的数据。
这是标准的design pattern，包括Facebook的论文《Scaling Memcache at Facebook》也使用了这个策略。为什么不是写完数据库后更新缓存？你可以看一下Quora上的这个问答《Why does Facebook use delete to remove the key-value pair in Memcached instead of updating the Memcached during write request to the backend?》，主要是怕两个并发的写操作导致脏数据。
那么，是不是Cache Aside这个就不会有并发问题了？不是的，比如，一个是读操作，但是没有命中缓存，然后就到数据库中取数据，此时来了一个写操作，写完数据库后，让缓存失效，然后，之前的那个读操作再把老的数据放进去，所以，会造成脏数据。
但，这个case理论上会出现，不过，实际上出现的概率可能非常低，因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，而读操作必需在写操作前进入数据库操作，而又要晚于写操作更新缓存，所有的这些条件都具备的概率基本并不大。
所以，这也就是Quora上的那个答案里说的，要么通过2PC或是Paxos协议保证一致性，要么就是拼命的降低并发时脏数据的概率，而Facebook使用了这个降低概率的玩法，因为2PC太慢，而Paxos太复杂。当然，最好还是为缓存设置上过期时间。
Read/Write Through Pattern
我们可以看到，在上面的Cache Aside套路中，我们的应用代码需要维护两个数据存储，一个是缓存（Cache），一个是数据库（Repository）。所以，应用程序比较啰嗦。而Read/Write Through套路是把更新数据库（Repository）的操作由缓存自己代理了，所以，对于应用层来说，就简单很多了。可以理解为，应用认为后端就是一个单一的存储，而存储自己维护自己的Cache。
Read Through
Read Through 套路就是在查询操作中更新缓存，也就是说，当缓存失效的时候（过期或LRU换出），Cache Aside是由调用方负责把数据加载入缓存，而Read Through则用缓存服务自己来加载，从而对应用方是透明的。
Write Through
Write Through 套路和Read Through相仿，不过是在更新数据时发生。当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后再由Cache自己更新数据库（这是一个同步操作）
下图自来Wikipedia的Cache词条。其中的Memory你可以理解为就是我们例子里的数据库。
Write Behind Caching Pattern
Write Behind 又叫 Write Back。一些了解Linux操作系统内核的同学对write back应该非常熟悉，这不就是Linux文件系统的Page Cache的算法吗？是的，你看基础这玩意全都是相通的。所以，基础很重要，我已经不是一次说过基础很重要这事了。
Write Back套路，一句说就是，在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。这个设计的好处就是让数据的I/O操作飞快无比（因为直接操作内存嘛 ），因为异步，write backg还可以合并对同一个数据的多次操作，所以性能的提高是相当可观的。
但是，其带来的问题是，数据不是强一致性的，而且可能会丢失（我们知道Unix/Linux非正常关机会导致数据丢失，就是因为这个事）。在软件设计上，我们基本上不可能做出一个没有缺陷的设计，就像算法设计中的时间换空间，空间换时间一个道理，有时候，强一致性和高性能，高可用和高性性是有冲突的。软件设计从来都是取舍Trade-Off。
另外，Write Back实现逻辑比较复杂，因为他需要track有哪数据是被更新了的，需要刷到持久层上。操作系统的write back会在仅当这个cache需要失效的时候，才会被真正持久起来，比如，内存不够了，或是进程退出了等情况，这又叫lazy write。
在wikipedia上有一张write back的流程图，基本逻辑如下：
&amp;nbsp;
再多唠叨一些
1）上面讲的这些Design Pattern，其实并不是软件架构里的mysql数据库和memcache/redis的更新策略，这些东西都是计算机体系结构里的设计，比如CPU的缓存，硬盘文件系统中的缓存，硬盘上的缓存，数据库中的缓存。基本上来说，这些缓存更新的设计模式都是非常老古董的，而且历经长时间考验的策略，所以这也就是，工程学上所谓的Best Practice，遵从就好了。
2）有时候，我们觉得能做宏观的系统架构的人一定是很有经验的，其实，宏观系统架构中的很多设计都来源于这些微观的东西。比如，云计算中的很多虚拟化技术的原理，和传统的虚拟内存不是很像么？Unix下的那些I/O模型，也放大到了架构里的同步异步的模型，还有Unix发明的管道不就是数据流式计算架构吗？TCP的好些设计也用在不同系统间的通讯中，仔细看看这些微观层面，你会发现有很多设计都非常精妙……所以，请允许我在这里放句观点鲜明的话——如果你要做好架构，首先你得把计算机体系结构以及很多老古董的基础技术吃透了。
3）在软件开发或设计中，我非常建议在之前先去参考一下已有的设计和思路，看看相应的guideline，best practice或design pattern，吃透了已有的这些东西，再决定是否要重新发明轮子。千万不要似是而非地，想当然的做软件设计。
4）上面，我们没有考虑缓存（Cache）和持久层（Repository）的整体事务的问题。比如，更新Cache成功，更新数据库失败了怎么吗？或是反过来。关于这个事，如果你需要强一致性，你需要使用“两阶段提交协议”——prepare, commit/rollback，比如Java 7 的XAResource，还有MySQL 5.7的 XA Transaction，有些cache也支持XA，比如EhCache。当然，XA这样的强一致性的玩法会导致性能下降，关于分布式的事务的相关话题，你可以看看《分布式系统的事务处理》一文。
（全文完）
&amp;nbsp;
&amp;nbsp;
关注CoolShell微信公众账号可以在手机端搜索文章
（转载本站文章请注明作者和出处 酷 壳 &amp;#8211; CoolShell ，请勿用于任何商业用途）
——=== 访问 酷壳404页面 寻找遗失儿童。 ===——
</Content>
    </doc>
    <doc>
        <docid>11</docid>
        <title>为什么我不在微信公众号上写文章</title>
        <link>http://coolshell.cn/articles/17391.html</link>
        <Content></Content>
    </doc>
    <doc>
        <docid>12</docid>
        <title>性能测试应该怎么做？</title>
        <link>http://coolshell.cn/articles/17381.html</link>
        <Content>偶然间看到了阿里中间件Dubbo的性能测试报告，我觉得这份性能测试报告让人觉得做这性能测试的人根本不懂性能测试，我觉得这份报告会把大众带沟里去，所以，想写下这篇文章，做一点科普。
首先，这份测试报告里的主要问题如下：
1）用的全是平均值。老实说，平均值是非常不靠谱的。
2）响应时间没有和吞吐量TPS/QPS挂钩。而只是测试了低速率的情况，这是完全错误的。
3）响应时间和吞吐量没有和成功率挂钩。
为什么平均值不靠谱
关于平均值为什么不靠谱，我相信大家读新闻的时候经常可以看到，平均工资，平均房价，平均支出，等等这样的字眼，你就知道为什么平均值不靠谱了。（这些都是数学游戏，对于理工科的同学来说，天生应该有免疫力）
软件的性能测试也一样，平均数也是不靠谱的，这里可以参看这篇详细的文章《Why Averages Suck and Percentiles are Great》，我在这里简单说一下。
我们知道，性能测试时，测试得到的结果数据不总是一样的，而是有高有低的，如果算平均值就会出现这样的情况，假如，测试了10次，有9次是1ms，而有1次是1s，那么平均数据就是100ms，很明显，这完全不能反应性能测试的情况，也许那1s的请求就是一个不正常的值，是个噪点，应该去掉。所以，我们会在一些评委打分中看到要去掉一个最高分一个最低分，然后再算平均值。
另外，中位数（Mean）可能会比平均数要稍微靠谱一些，所谓中位数的意就是把将一组数据按大小顺序排列，处在最中间位置的一个数叫做这组数据的中位数 ，这意味着至少有50%的数据低于或高于这个中位数。
当然，最为正确的统计做法是用百分比分布统计。也就是英文中的TP &amp;#8211; Top Percentile ，TP50的意思在，50%的请求都小于某个值，TP90表示90%的请求小于某个时间。
比如：我们有一组数据：[ 10ms,  1s, 200ms, 100ms]，我们把其从小到大排个序：[10ms, 100ms, 200ms, 1s]，于是我们知道，TP50，就是50%的请求ceil(4*0.5)=2时间是小于100ms的，TP90就是90%的请求ceil(4*0.9)=4时间小于1s。于是：TP50就是100ms，TP90就是1s。
我以前在路透做的金融系统响应时间的性能测试的要求是这样的，99.9%的请求必须小于1ms，所有的平均时间必须小于1ms。两个条件的限制。
为什么响应时间（latency）要和吞吐量（Thoughput）挂钩
系统的性能如果只看吞吐量，不看响应时间是没有意义的。我的系统可以顶10万请求，但是响应时间已经到了5秒钟，这样的系统已经不可用了，这样的吞吐量也是没有意义的。
我们知道，当并发量（吞吐量）上涨的时候，系统会变得越来越不稳定，响应时间的波动也会越来越大，响应时间也会变得越来越慢，而吞吐率也越来越上不去（如下图所示），包括CPU的使用率情况也会如此。所以，当系统变得不稳定的时候，吞吐量已经没有意义了。吞吐量有意义的时候仅当系统稳定的时候。
所以，吞吐量的值必需有响应时间来卡。比如：TP99小于100ms的时候，系统可以承载的最大并发数是1000qps。这意味着，我们要不断的在不同的并发数上测试，以找到软件的最稳定时的最大吞吐量。
&amp;nbsp;
为什么响应时间吞吐量和成功率要挂钩
我们这应该不难理解了，如果请求不成功的话，都还做毛的性能测试。比如，我说我的系统并发可以达到10万，但是失败率是
40%，那么，这10万的并发完全就是一个笑话了。
性能测试的失败率的容忍应该是非常低的。对于一些关键系统，成功请求数必须在100%，一点都不能含糊。
&amp;nbsp;
如何严谨地做性能测试
一般来说，性能测试要统一考虑这么几个因素：Thoughput吞吐量，Latency响应时间，资源利用（CPU/MEM/IO/Bandwidth&amp;#8230;），成功率，系统稳定性。
下面的这些性能测试的方式基本上来源自我的老老东家汤森路透，一家做real-time的金融数据系统的公司。
一，你得定义一个系统的响应时间latency，建议是TP99，以及成功率。比如路透的定义：99.9%的响应时间必需在1ms之内，平均响应时间在1ms以内，100%的请求成功。
二，在这个响应时间的限制下，找到最高的吞吐量。测试用的数据，需要有大中小各种尺寸的数据，并可以混合。最好使用生产线上的测试数据。
三，在这个吞吐量做Soak Test，比如：使用第二步测试得到的吞吐量连续7天的不间断的压测系统。然后收集CPU，内存，硬盘/网络IO，等指标，查看系统是否稳定，比如，CPU是平稳的，内存使用也是平稳的。那么，这个值就是系统的性能
四，找到系统的极限值。比如：在成功率100%的情况下（不考虑响应时间的长短），系统能坚持10分钟的吞吐量。
五，做Burst Test。用第二步得到的吞吐量执行5分钟，然后在第四步得到的极限值执行1分钟，再回到第二步的吞吐量执行5钟，再到第四步的权限值执行1分钟，如此往复个一段时间，比如2天。收集系统数据：CPU、内存、硬盘/网络IO等，观察他们的曲线，以及相应的响应时间，确保系统是稳定的。
六、低吞吐量和网络小包的测试。有时候，在低吞吐量的时候，可能会导致latency上升，比如TCP_NODELAY的参数没有开启会导致latency上升（详见TCP的那些事），而网络小包会导致带宽用不满也会导致性能上不去，所以，性能测试还需要根据实际情况有选择的测试一下这两咱场景。
（注：在路透，路透会用第二步得到的吞吐量乘以66.7%来做为系统的软报警线，80%做为系统的硬报警线，而极限值仅仅用来扛突发的peak）
是不是很繁锁？是的，只因为，这是工程，工程是一门科学，科学是严谨的。
欢迎大家也分享一下你们性能测试的经验和方法。
（全文完）
&amp;nbsp;
关注CoolShell微信公众账号可以在手机端搜索文章
（转载本站文章请注明作者和出处 酷 壳 &amp;#8211; CoolShell ，请勿用于任何商业用途）
——=== 访问 酷壳404页面 寻找遗失儿童。 ===——
</Content>
    </doc>
    <doc>
        <docid>13</docid>
        <title>让我们来谈谈分工</title>
        <link>http://coolshell.cn/articles/17295.html</link>
        <Content></Content>
    </doc>
    <doc>
        <docid>14</docid>
        <title>Cuckoo Filter：设计与实现</title>
        <link>http://coolshell.cn/articles/17225.html</link>
        <Content>（感谢网友 @我的上铺叫路遥 投稿）
对于海量数据处理业务，我们通常需要一个索引数据结构，用来帮助查询，快速判断数据记录是否存在，这种数据结构通常又叫过滤器(filter)。考虑这样一个场景，上网的时候需要在浏览器上输入URL，这时浏览器需要去判断这是否一个恶意的网站，它将对本地缓存的成千上万的URL索引进行过滤，如果不存在，就放行，如果（可能）存在，则向远程服务端发起验证请求，并回馈客户端给出警告。
索引的存储又分为有序和无序，前者使用关联式容器，比如B树，后者使用哈希算法。这两类算法各有优劣：比如，关联式容器时间复杂度稳定O(logN)，且支持范围查询；又比如哈希算法的查询、增删都比较快O(1)，但这是在理想状态下的情形，遇到碰撞严重的情况，哈希算法的时间复杂度会退化到O(n)。因此，选择一个好的哈希算法是很重要的。
时下一个非常流行的哈希索引结构就是bloom filter，它类似于bitmap这样的hashset，所以空间利用率很高。其独特的地方在于它使用多个哈希函数来避免哈希碰撞，如图所示（来源wikipedia），bit数组初始化为全0，插入x时，x被3个哈希函数分别映射到3个不同的bit位上并置1，查询x时，只有被这3个函数映射到的bit位全部是1才能说明x可能存在，但凡至少出现一个0表示x肯定不存在。
但是，bloom filter的这种位图模式带来两个问题：一个是误报（false positives），在查询时能提供“一定不存在”，但只能提供“可能存在”，因为存在其它元素被映射到部分相同bit位上，导致该位置1，那么一个不存在的元素可能会被误报成存在；另一个是漏报（false nagatives），同样道理，如果删除了某个元素，导致该映射bit位被置0，那么本来存在的元素会被漏报成不存在。由于后者问题严重得多，所以bloom filter必须确保“definitely no”从而容忍“probably yes”，不允许元素的删除。
关于元素删除的问题，一个改良方案是对bloom filter引入计数，但这样一来，原来每个bit空间就要扩张成一个计数值，空间效率上又降低了。
Cuckoo Hashing
为了解决这一问题，本文引入了一种新的哈希算法——cuckoo filter，它既可以确保该元素存在的必然性，又可以在不违背此前提下删除任意元素，仅仅比bitmap牺牲了微量空间效率。先说明一下，这个算法的思想来源是一篇CMU论文，笔者按照其思路用C语言做了一个简单实现（Github），附上对一段文本数据进行导入导出的正确性测试。
</Content>
    </doc>
</lib>
